<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xmlns="http://www.oasis-open.org/docbook/4.5" xmlns:xl="http://www.w3.org/1999/xlink"
	xsi:schemaLocation="http://www.oasis-open.org/docbook/4.5 http://www.oasis-open.org/docbook/xsd/4.5/docbook.xsd">

	<title>Architecture</title>

	<chapterinfo>
		<abstract>
			<para>
				The architecture of DataCleaner can be described from different
				angles depending on the topic of interest. In the following sections
				we cover different aspects of the DataCleaner architecture.
			</para>
		</abstract>
	</chapterinfo>

	<section id="architecture_data_access">
		<title>Data access</title>

		<para>In DataCleaner all sources of data are called 'datastores'. This
			concept covers both sources that are read/parsed locally and those
			that are 'connected to', eg. databases and applications. Some
			datastores can also be written to, for instance relational databases.
		</para>

		<para>
			DataCleaner uses the
			<link xl:href="http://metamodel.apache.org">Apache MetaModel framework</link>
			for data access. From DataCleaner's perspective, Apache MetaModel
			provides a
			number of features:
		</para>
		<orderedlist>
			<listitem>
				<para>A common way of interacting with different datastores.</para>
			</listitem>
			<listitem>
				<para>A programmatic query syntax that abstracts away
					database-specific SQL dialects, and that is usable also for non-SQL
					oriented datastores (files etc.).
				</para>
			</listitem>
			<listitem>
				<para>Out-of-the-box connectivity to a lot of sources, eg. CSV
					files, relational databases, Excel spreadsheets and a lot more.
				</para>
			</listitem>
			<listitem>
				<para>A framework for modelling new sources using the same common
					model.
				</para>
			</listitem>
		</orderedlist>

		<para>
			DataCleaners datastore model is also extensible in the way that
			you
			can yourself implement new datastores in order to hook up
			DataCleaner
			to legacy systems, application interfaces and more. For more
			information refer to the
			<link linkend="section_development_tutorials">Developer resources</link>
			chapter.
		</para>

	</section>
	<section id="architecture_processing_framework">
		<title>Processing framework</title>

		<para>The way DataCleaner processes data is
			slightly different compared
			to most similar (ETL-like) tools. Firstly in the way multithreading
			is applied, secondly in the way DataCleaner may sometimes optimize
			the graph at execution time.
		</para>

		<para>
			<emphasis>Multithreading:</emphasis>
			The multithreading strategy in DataCleaner enables the tool to have
			the minimum amount of blocking and buffering and the maximum amount
			of parallelism and potentially also distribution. Most ETL-like tools
			apply a threading strategy where each component in a job has it's own
			thread-management as well as an input- and an output-buffer. In
			DataCleaner the thread management is made such that every record is
			processed in parallel - each unit of work is stepping through the
			complete job graph in one single pass. This has a number of
			interesting traits:
		</para>
		<orderedlist>
			<listitem>
				<para>There's is a high degree of automatic 'load balancing' among
					the components - less constraints and bottlenecks around the
					slowest components in the job.
				</para>
			</listitem>
			<listitem>
				<para>The system lends itself to highly distributed processing
					because statefulness is the exception instead of the
					rule.
				</para>
			</listitem>
			<listitem>
				<para>There is less waste in the form of buffers inbetween the
					components of a job.
				</para>
			</listitem>
			<listitem>
				<para>One downside to this approach is that the order of the
					processed records cannot be guaranteed. This is only very rarely
					required in the domain of data profiling and analysis, and if it is
					required there are technical workarounds to apply.
				</para>
			</listitem>
		</orderedlist>

		<para>
			<emphasis>Graph optimization:</emphasis>
			While a job graph (see
			<link linkend="wiring_components">wiring components together</link>
			) may show a particular following order, the engine may at runtime do
			certain optimizations to it. Some components may provide optimization
			strategies that involves changing the source query so that the number
			of (or content of) processed records is changed. Obviously this is a
			side-effect of using a component that will only be applied in cases
			where it does not impact other components in a job. The principle is
			sometimes also referred to as 'Push down optimization'.
		</para>
		<para>
			An example of this is a 'Null check' filter: If a Null check is
			applied on a source column and all other components require either a
			NULL or a NOT_NULL outcome (either explicitly or implicitly), then
			the 'Null check' filter may add a predicate to the source query to
			filter out all irrelevant records. For more information on this
			principle, please read the blog entry '
			<link
				xl:href="http://kasper.eobjects.org/2011/12/push-down-query-optimization-in.html">Push down query optimization in DataCleaner</link>
			' by Kasper SÃ¸rensen.
		</para>

	</section>

</chapter>
